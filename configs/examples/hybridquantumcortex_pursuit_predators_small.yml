# Hybrid Quantum Cortex Brain - Stage 2: QSNN Cortex + Critic Training
# Loads pre-trained reflex weights (frozen) and trains the QSNN cortex
# via REINFORCE with critic-provided GAE advantages for multi-objective
# behaviour (foraging + predator evasion).
#
# QSNN reflex params MUST match stage 1 config exactly (6/8/4 neurons,
# legacy 2-feature mode) so that pre-trained weights load correctly.
# The cortex QSNN gets its own sensory input via cortex_sensory_modules.
#
# To use: update reflex_weights_path to point to your stage 1 weights file.

max_steps: 500
brain:
  name: hybridquantumcortex
  config:
    # Training stage: 2 = cortex REINFORCE+GAE (reflex frozen)
    training_stage: 2

    # Path to pre-trained reflex weights from stage 1
    # Update this path to your actual stage 1 output
    reflex_weights_path: artifacts/models/stage1/reflex_weights.pt

    # QSNN reflex params (must match stage 1 config exactly)
    num_sensory_neurons: 6
    num_hidden_neurons: 8
    num_motor_neurons: 4
    membrane_tau: 0.9
    threshold: 0.5
    refractory_period: 0
    shots: 1024
    num_qsnn_timesteps: 10
    surrogate_alpha: 1.0
    logit_scale: 5.0
    weight_clip: 3.0
    theta_motor_max_norm: 1.0

    # Cortex QSNN params
    cortex_neurons_per_group: 4
    cortex_hidden_neurons: 12
    cortex_output_neurons: 8
    num_cortex_timesteps: 4
    cortex_shots: 100
    num_modes: 3

    # Cortex sensory modules (3 modalities, 6 features total)
    cortex_sensory_modules:
      - food_chemotaxis
      - nociception
      - mechanosensation

    # Cortex REINFORCE+GAE params
    cortex_lr: 0.01
    critic_lr: 0.001
    num_cortex_reinforce_epochs: 2
    ppo_buffer_size: 512
    gae_lambda: 0.95
    entropy_coeff: 0.02
    max_grad_norm: 0.5
    use_gae_advantages: true
    gamma: 0.99

    # Cortex LR schedule (warmup + decay)
    cortex_lr_warmup_episodes: 50
    cortex_lr_warmup_start: 0.001
    cortex_lr_decay_episodes: 200
    cortex_lr_decay_end: 0.001

    # Critic MLP params
    critic_hidden_dim: 64
    critic_num_layers: 2

body_length: 2

reward:
  reward_goal: 2.0
  reward_distance_scale: 0.5
  reward_exploration: 0.05
  penalty_step: 0.005
  penalty_anti_dithering: 0.02
  penalty_stuck_position: 0
  penalty_starvation: 10.0
  penalty_predator_death: 10.0
  penalty_predator_proximity: 0.15
  stuck_position_threshold: 0
  penalty_boundary_collision: 0.02
  penalty_health_damage: 0.5
  reward_health_gain: 0.1

satiety:
  initial_satiety: 300.0
  satiety_decay_rate: 0.8
  satiety_gain_per_food: 0.2

environment:
  grid_size: 20
  viewport_size: [11, 11]
  use_separated_gradients: true

  foraging:
    foods_on_grid: 6
    target_foods_to_collect: 10
    min_food_distance: 3
    agent_exclusion_radius: 5
    gradient_decay_constant: 8.0
    gradient_strength: 1.0

  predators:
    enabled: true
    count: 2
    speed: 0.5
    movement_pattern: pursuit
    detection_radius: 6
    kill_radius: 0
    gradient_decay_constant: 10.0
    gradient_strength: 1.0

  health:
    enabled: true
    max_hp: 100.0
    predator_damage: 20.0
    food_healing: 10.0

gradient:
  method: clip
