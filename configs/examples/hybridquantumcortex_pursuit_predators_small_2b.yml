# Hybrid Quantum Cortex Brain - Stage 2b: Cortex with 1 Slow Predator
# Second step of the graduated cortex curriculum.
# Trains cortex from scratch with nociception added for predator awareness.
# Uses a single slow predator with doubled HP (200) for gentler evasion learning.
#
# NOTE: Cortex weights from stage 2a CANNOT be reused here because stage 2a
# has 1 sensory group (food_chemotaxis only) while 2b has 2 groups
# (food_chemotaxis + nociception), changing all weight dimensions.
#
# Curriculum: 2a (foraging) → 2b (1 predator, easy) → 2c (2 predators, full)
#
# To use: update reflex_weights_path to point to your stage 1 weights file.

max_steps: 500
brain:
  name: hybridquantumcortex
  config:
    # Training stage: 2 = cortex REINFORCE+GAE (reflex frozen)
    training_stage: 2

    # Path to pre-trained reflex weights from stage 1
    reflex_weights_path: artifacts/models/20260218_131409/reflex_weights.pt

    # No cortex_weights_path — cortex trains from scratch with new sensory groups

    # QSNN reflex params (must match stage 1 config exactly)
    num_sensory_neurons: 6
    num_hidden_neurons: 8
    num_motor_neurons: 4
    membrane_tau: 0.9
    threshold: 0.5
    refractory_period: 0
    shots: 1024
    num_qsnn_timesteps: 10
    surrogate_alpha: 1.0
    logit_scale: 5.0
    weight_clip: 3.0
    theta_motor_max_norm: 1.0

    # Cortex QSNN params
    cortex_neurons_per_group: 4
    cortex_hidden_neurons: 12
    cortex_output_neurons: 8
    num_cortex_timesteps: 4
    cortex_shots: 100
    num_modes: 3

    # Cortex sensory modules (need nociception for predator evasion)
    cortex_sensory_modules:
      - food_chemotaxis
      - nociception

    # Cortex REINFORCE+GAE params
    # 1 epoch only — multi-epoch is redundant due to caching (see stage 2b analysis)
    cortex_lr: 0.005
    critic_lr: 0.001
    critic_lr_independent: true
    num_cortex_reinforce_epochs: 1
    num_critic_epochs: 3
    ppo_buffer_size: 512
    gae_lambda: 0.95
    entropy_coeff: 0.10
    max_grad_norm: 0.5
    use_gae_advantages: true
    gamma: 0.99

    # Cortex LR schedule (warmup + decay)
    cortex_lr_warmup_episodes: 30
    cortex_lr_warmup_start: 0.001
    cortex_lr_decay_episodes: 150
    cortex_lr_decay_end: 0.001

    # Cortex adaptive alpha scheduling
    # Alpha warmup delayed past LR warmup to avoid double amplification
    cortex_alpha_start: 0.3
    cortex_alpha_end: 2.0
    cortex_alpha_warmup_episodes: 150
    cortex_alpha_warmup_delay: 30

    # Critic MLP params
    critic_hidden_dim: 64
    critic_num_layers: 2

body_length: 2

reward:
  reward_goal: 2.0
  reward_distance_scale: 0.5
  reward_exploration: 0.05
  penalty_step: 0.005
  penalty_anti_dithering: 0.02
  penalty_stuck_position: 0
  penalty_starvation: 4.0
  penalty_predator_death: 10.0
  penalty_predator_proximity: 0.05
  stuck_position_threshold: 0
  penalty_boundary_collision: 0.02
  penalty_health_damage: 0.3
  reward_health_gain: 0.1

satiety:
  initial_satiety: 300.0
  satiety_decay_rate: 0.8
  satiety_gain_per_food: 0.2

environment:
  grid_size: 20
  viewport_size: [11, 11]
  use_separated_gradients: true

  foraging:
    foods_on_grid: 6
    target_foods_to_collect: 10
    min_food_distance: 3
    agent_exclusion_radius: 5
    gradient_decay_constant: 8.0
    gradient_strength: 1.0

  predators:
    enabled: true
    count: 1
    speed: 0.3
    movement_pattern: pursuit
    detection_radius: 5
    kill_radius: 0
    gradient_decay_constant: 10.0
    gradient_strength: 1.0

  health:
    enabled: true
    max_hp: 200.0
    predator_damage: 15.0
    food_healing: 10.0

gradient:
  method: clip
