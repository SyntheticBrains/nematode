# Dynamic Foraging with Predators - Small Configuration
# Introduces predator evasion challenge in an easy 20x20 environment
# Uses MLP (classical neural network) brain architecture
# Multi-objective learning: find food while avoiding predators

max_steps: 500
brain:
  name: mlp
  config:
    baseline: 0.0
    baseline_alpha: 0.05
    entropy_beta: 0.01
    gamma: 0.99
    hidden_dim: 64
    learning_rate: 0.001
    lr_scheduler_step_size: 100
    lr_scheduler_gamma: 0.9
    num_hidden_layers: 2

body_length: 2

learning_rate:
  method: dynamic
  parameters:
    initial_learning_rate: 0.001
    decay_type: exponential
    decay_rate: 0.9995
    min_lr: 0.0003

# Reward configuration with predator death penalty
reward:
  reward_goal: 2.0
  reward_distance_scale: 0.5
  reward_exploration: 0.05  # Bonus for visiting new cells
  penalty_step: 0.005
  penalty_anti_dithering: 0.02
  penalty_stuck_position: 0.1
  penalty_starvation: 10.0
  penalty_predator_death: 10.0
  stuck_position_threshold: 3

# Satiety configuration
satiety:
  initial_satiety: 200.0
  satiety_decay_rate: 1.0
  satiety_gain_per_food: 0.2  # Restore 20% of max satiety per food

# Dynamic environment with foraging and predators
environment:
  type: dynamic
  dynamic:
    grid_size: 20
    viewport_size: [11, 11]

    # Foraging configuration (food mechanics)
    foraging:
      num_initial_foods: 5
      max_active_foods: 10
      min_food_distance: 3
      agent_exclusion_radius: 5
      gradient_decay_constant: 8.0
      gradient_strength: 1.0

    # Predator configuration (evasion mechanics)
    predators:
      enabled: true
      count: 2
      speed: 1.0
      movement_pattern: random
      detection_radius: 8
      kill_radius: 0
      gradient_decay_constant: 12.0
      gradient_strength: 1.0
      proximity_penalty: -0.1

gradient:
  method: clip
