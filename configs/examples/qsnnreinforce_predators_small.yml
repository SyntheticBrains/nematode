# Dynamic Foraging with Random Predators - Small Configuration
# Dual-objective: forage while evading randomly moving predators
# Uses QSNN REINFORCE (Quantum Spiking Neural Network) brain architecture
# Surrogate gradient learning (REINFORCE + QLIFSurrogateSpike backprop + PPO clipping)
#
# Sensory modules: food_chemotaxis (2 features), nociception (2 features)

max_steps: 500
brain:
  name: qsnnreinforce
  config:
    num_sensory_neurons: 4
    num_hidden_neurons: 10
    num_motor_neurons: 4
    membrane_tau: 0.9
    threshold: 0.5
    refractory_period: 0
    use_local_learning: false
    shots: 1024
    gamma: 0.99
    learning_rate: 0.01
    entropy_coef: 0.08
    weight_clip: 2.0
    update_interval: 20
    num_integration_steps: 10
    exploration_decay_episodes: 120
    lr_decay_episodes: 400
    lr_min_factor: 0.2
    logit_scale: 5.0
    sensory_modules:
      - food_chemotaxis
      - nociception

body_length: 2

reward:
  reward_goal: 2.0
  reward_distance_scale: 0.5
  reward_exploration: 0.05
  penalty_step: 0.005
  penalty_anti_dithering: 0.02
  penalty_stuck_position: 0
  penalty_starvation: 2.0
  penalty_predator_death: 3.0
  penalty_predator_proximity: 0.05
  stuck_position_threshold: 0
  penalty_boundary_collision: 0.02

satiety:
  initial_satiety: 200.0
  satiety_decay_rate: 1.0
  satiety_gain_per_food: 0.2

environment:
  grid_size: 20
  viewport_size: [11, 11]
  use_separated_gradients: true

  foraging:
    foods_on_grid: 5
    target_foods_to_collect: 10
    min_food_distance: 3
    agent_exclusion_radius: 5
    gradient_decay_constant: 8.0
    gradient_strength: 1.0

  predators:
    enabled: true
    count: 2
    speed: 1.0
    movement_pattern: random
    detection_radius: 8
    kill_radius: 0
    gradient_decay_constant: 8.0
    gradient_strength: 1.0

gradient:
  method: clip
