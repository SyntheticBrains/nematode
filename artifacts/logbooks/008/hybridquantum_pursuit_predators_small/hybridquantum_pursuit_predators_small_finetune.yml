# Hybrid Quantum Brain - Stage 3: Joint Fine-Tune
# Loads both pre-trained QSNN and cortex weights, then fine-tunes jointly.
# QSNN is unfrozen with 10x lower LR (0.001 vs 0.01) to preserve reflexes.
# Cortex continues PPO training with lower base LR (already partially trained).
#
# QSNN reflex params MUST match stage 1 config exactly (6/8/4 neurons,
# legacy 2-feature mode) so that pre-trained weights load correctly.
# Cortex params MUST match stage 2 config exactly (64x2, 3 modes, 6 features).
#
# Weight sources:
#   QSNN: Stage 1 best (session 100512, 100% post-convergence foraging)
#   Cortex: Stage 2 Round 3 best (session 012735, 91.5% post-convergence)
#
# To use: update qsnn_weights_path and cortex_weights_path to your files.

max_steps: 500
brain:
  name: hybridquantum
  config:
    # Training stage: 3 = joint fine-tune (both QSNN + cortex trainable)
    training_stage: 3

    # Paths to pre-trained weights
    qsnn_weights_path: artifacts/models/20260216_100512/qsnn_weights.pt
    cortex_weights_path: artifacts/models/20260217_012735/cortex_weights.pt

    # QSNN reflex params (must match stage 1 config exactly)
    num_sensory_neurons: 6
    num_hidden_neurons: 8
    num_motor_neurons: 4
    membrane_tau: 0.9
    threshold: 0.5
    refractory_period: 0
    shots: 1024
    num_qsnn_timesteps: 10
    surrogate_alpha: 1.0
    logit_scale: 5.0
    weight_clip: 3.0
    theta_motor_max_norm: 1.0

    # QSNN REINFORCE params (active in stage 3)
    # Base LR = 0.01, reduced to 0.001 by joint_finetune_lr_factor
    qsnn_lr: 0.01
    joint_finetune_lr_factor: 0.1
    qsnn_lr_decay_episodes: 200
    num_reinforce_epochs: 2
    reinforce_window_size: 20
    gamma: 0.99
    advantage_clip: 2.0
    clip_epsilon: 0.2
    lr_min_factor: 0.1

    # Cortex params (must match stage 2 config exactly)
    cortex_hidden_dim: 64
    cortex_num_layers: 2
    num_modes: 3

    # Cortex PPO params (active in stage 3)
    # Lower base LR than stage 2 since cortex is already trained
    cortex_actor_lr: 0.0005
    cortex_critic_lr: 0.0005
    ppo_clip_epsilon: 0.2
    ppo_epochs: 12
    ppo_minibatches: 4
    ppo_buffer_size: 512
    gae_lambda: 0.95
    entropy_coeff: 0.01
    max_grad_norm: 0.5

    # Cortex LR schedule (gentle warmup + decay for fine-tuning)
    cortex_lr_warmup_episodes: 20
    cortex_lr_warmup_start: 0.0001
    cortex_lr_decay_episodes: 100
    cortex_lr_decay_end: 0.0001

    # Sensory modules for cortex (must match stage 2 config exactly)
    sensory_modules:
      - food_chemotaxis
      - nociception
      - mechanosensation

body_length: 2

reward:
  reward_goal: 2.0
  reward_distance_scale: 0.5
  reward_exploration: 0.05
  penalty_step: 0.005
  penalty_anti_dithering: 0.02
  penalty_stuck_position: 0
  penalty_starvation: 10.0
  penalty_predator_death: 10.0
  penalty_predator_proximity: 0.15
  stuck_position_threshold: 0
  penalty_boundary_collision: 0.02
  penalty_health_damage: 0.5
  reward_health_gain: 0.1

satiety:
  initial_satiety: 300.0
  satiety_decay_rate: 0.8
  satiety_gain_per_food: 0.2

environment:
  grid_size: 20
  viewport_size: [11, 11]
  use_separated_gradients: true

  foraging:
    foods_on_grid: 6
    target_foods_to_collect: 10
    min_food_distance: 3
    agent_exclusion_radius: 5
    gradient_decay_constant: 8.0
    gradient_strength: 1.0

  predators:
    enabled: true
    count: 2
    speed: 0.5
    movement_pattern: pursuit
    detection_radius: 6
    kill_radius: 0
    gradient_decay_constant: 10.0
    gradient_strength: 1.0

  health:
    enabled: true
    max_hp: 100.0
    predator_damage: 20.0
    food_healing: 10.0

gradient:
  method: clip
